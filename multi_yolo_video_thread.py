import os
import sys
import argparse
import threading
import multiprocessing as mp
import time
import tkinter as tk
from tkinter import filedialog, ttk, messagebox
import cv2
import torch
from ultralytics import YOLO
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.figure import Figure
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import matplotlib
from concurrent.futures import ThreadPoolExecutor

# Set environment variable to avoid OpenMP conflicts
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# è¨­ç½®matplotlibæ”¯æŒä¸­æ–‡é¡¯ç¤º
matplotlib.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'sans-serif']
matplotlib.rcParams['axes.unicode_minus'] = False

# ===== å¤šé€²ç¨‹å·¥ä½œå‡½å¼ =====
def player_process_worker(frames, result_dict, player_model_path, device):
    """çƒå“¡åµæ¸¬å¤šé€²ç¨‹å·¥ä½œå‡½å¼"""
    model = YOLO(player_model_path).to(device)
    results = {}
    times = {}
    for i, frame in enumerate(frames):
        with torch.no_grad():
            start = time.time()
            result = model.track(source=frame, conf=0.3, persist=True, tracker="bytetrack.yaml")
            end = time.time()
        inference_time = end - start
        results[i] = result
        times[i] = inference_time
        print(f"[å¤šé€²ç¨‹] çƒå“¡åµæ¸¬ Frame-{i} å®Œæˆï¼Œè€—æ™‚: {inference_time:.3f} ç§’")
    result_dict['player_results'] = results
    result_dict['player_times'] = times

def court_process_worker(frames, result_dict, court_model_path, device):
    """çƒå ´åµæ¸¬å¤šé€²ç¨‹å·¥ä½œå‡½å¼"""
    model = YOLO(court_model_path).to(device)
    results = {}
    times = {}
    for i, frame in enumerate(frames):
        with torch.no_grad():
            start = time.time()
            result = model.track(source=frame, conf=0.25, persist=True, tracker="bytetrack.yaml")
            end = time.time()
        inference_time = end - start
        results[i] = result
        times[i] = inference_time
        print(f"[å¤šé€²ç¨‹] çƒå ´åµæ¸¬ Frame-{i} å®Œæˆï¼Œè€—æ™‚: {inference_time:.3f} ç§’")
    result_dict['court_results'] = results
    result_dict['court_times'] = times

# ===== ä½‡åˆ—å·¥ä½œå‡½å¼ =====
def player_queue_worker(task_queue, result_queue, player_model_path, device):
    """çƒå“¡åµæ¸¬ä½‡åˆ—å·¥ä½œå‡½å¼"""
    print("[çƒå“¡ä½‡åˆ—å·¥ä½œé€²ç¨‹] å•Ÿå‹•ï¼Œè¼‰å…¥æ¨¡å‹ä¸­...")
    model = YOLO(player_model_path).to(device)
    with torch.no_grad():
        while True:
            task = task_queue.get()
            if task is None:
                print("[çƒå“¡ä½‡åˆ—å·¥ä½œé€²ç¨‹] æ”¶åˆ°çµæŸè¨Šè™Ÿï¼Œé€€å‡ºã€‚")
                break
            idx, frame = task
            start = time.time()
            res = model.track(source=frame, conf=0.3, persist=True, tracker="bytetrack.yaml")
            t = time.time() - start
            print(f"[çƒå“¡ä½‡åˆ—å·¥ä½œé€²ç¨‹] Frame-{idx} æ¨ç†å®Œæˆï¼Œè€—æ™‚: {t:.3f} ç§’")
            result_queue.put(('player', idx, res, t))

def court_queue_worker(task_queue, result_queue, court_model_path, device):
    """çƒå ´åµæ¸¬ä½‡åˆ—å·¥ä½œå‡½å¼"""
    print("[çƒå ´ä½‡åˆ—å·¥ä½œé€²ç¨‹] å•Ÿå‹•ï¼Œè¼‰å…¥æ¨¡å‹ä¸­...")
    model = YOLO(court_model_path).to(device)
    with torch.no_grad():
        while True:
            task = task_queue.get()
            if task is None:
                print("[çƒå ´ä½‡åˆ—å·¥ä½œé€²ç¨‹] æ”¶åˆ°çµæŸè¨Šè™Ÿï¼Œé€€å‡ºã€‚")
                break
            idx, frame = task
            start = time.time()
            res = model.track(source=frame, conf=0.25, persist=True, tracker="bytetrack.yaml")
            t = time.time() - start
            print(f"[çƒå ´ä½‡åˆ—å·¥ä½œé€²ç¨‹] Frame-{idx} æ¨ç†å®Œæˆï¼Œè€—æ™‚: {t:.3f} ç§’")
            result_queue.put(('court', idx, res, t))

# ===== å¤šé€²ç¨‹æ± å·¥ä½œå‡½å¼ï¼ˆæ”¯æ´æ¨¡å‹å¿«å–ï¼‰=====
def player_pool_worker_frame_sync(args):
    """çƒå“¡åµæ¸¬æ± å·¥ä½œå‡½å¼ - æ”¯æ´æ¨¡å‹å¿«å–"""
    frame, idx, model_path, device = args

    # æª¢æŸ¥æ˜¯å¦å·²åœ¨é€™å€‹é€²ç¨‹ä¸­è¼‰å…¥éæ¨¡å‹
    if not hasattr(player_pool_worker_frame_sync, 'model'):
        print(f"[é€²ç¨‹ {os.getpid()}] è¼‰å…¥çƒå“¡æ¨¡å‹")
        player_pool_worker_frame_sync.model = YOLO(model_path).to(device)

    with torch.no_grad():
        start = time.time()
        result = player_pool_worker_frame_sync.model.track(source=frame, conf=0.3, persist=True, tracker="bytetrack.yaml")
        inference_time = time.time() - start

    print(f"[å¤šé€²ç¨‹æ± ] çƒå“¡åµæ¸¬ Frame-{idx} å®Œæˆï¼Œè€—æ™‚: {inference_time:.3f} ç§’")
    return ('player', idx, result, inference_time)

def court_pool_worker_frame_sync(args):
    """çƒå ´åµæ¸¬æ± å·¥ä½œå‡½å¼ - æ”¯æ´æ¨¡å‹å¿«å–"""
    frame, idx, model_path, device = args

    # æª¢æŸ¥æ˜¯å¦å·²åœ¨é€™å€‹é€²ç¨‹ä¸­è¼‰å…¥éæ¨¡å‹
    if not hasattr(court_pool_worker_frame_sync, 'model'):
        print(f"[é€²ç¨‹ {os.getpid()}] è¼‰å…¥çƒå ´æ¨¡å‹")
        court_pool_worker_frame_sync.model = YOLO(model_path).to(device)

    with torch.no_grad():
        start = time.time()
        result = court_pool_worker_frame_sync.model.track(source=frame, conf=0.25, persist=True, tracker="bytetrack.yaml")
        inference_time = time.time() - start

    print(f"[å¤šé€²ç¨‹æ± ] çƒå ´åµæ¸¬ Frame-{idx} å®Œæˆï¼Œè€—æ™‚: {inference_time:.3f} ç§’")
    return ('court', idx, result, inference_time)

# åŠŸèƒ½é¸æ“‡å®å®šç¾©
MODE_SERIAL = 0
MODE_THREADING = 1
MODE_MULTIPROCESS = 2
MODE_QUEUE = 3
MODE_IMPROVED_THREADING = 4
MODE_MP_POOL = 5

class YOLODetector:
    def __init__(self, player_model_path, court_model_path):
        self.player_model_path = player_model_path
        self.court_model_path = court_model_path
        self.device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
        print(f"ä½¿ç”¨è£ç½®: {self.device}")

        self.player_model = None
        self.court_model = None
        
    def load_models(self):
        """é å…ˆè¼‰å…¥å…©å€‹æ¨¡å‹"""
        print("é å…ˆè¼‰å…¥æ¨¡å‹ä¸­...")
        start = time.time()
        self.player_model = YOLO(self.player_model_path).to(self.device)
        self.court_model = YOLO(self.court_model_path).to(self.device)

        with torch.no_grad():
            dummy_img = torch.zeros((1, 3, 640, 640), device=self.device)
            self.player_model.predict(source=dummy_img)
            self.court_model.predict(source=dummy_img)

        end = time.time()
        print(f"æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œè€—æ™‚: {end - start:.3f} ç§’")
    
    def warmup_mp_pool_models(self):
        """é ç†±å¤šé€²ç¨‹æ± æ¨¡å‹"""
        from concurrent.futures import ProcessPoolExecutor

        print("[å¤šé€²ç¨‹æ± ] é–‹å§‹é ç†±æ¨¡å‹...")
        warmup_start = time.time()

        dummy_frame = np.zeros((480, 640, 3), dtype=np.uint8)

        with ProcessPoolExecutor(max_workers=2) as executor:
            player_warmup = executor.submit(
                player_pool_worker_frame_sync,
                (dummy_frame, -1, self.player_model_path, self.device)
            )
            court_warmup = executor.submit(
                court_pool_worker_frame_sync,
                (dummy_frame, -1, self.court_model_path, self.device)
            )

            player_warmup.result()
            court_warmup.result()

        warmup_time = time.time() - warmup_start
        print(f"[å¤šé€²ç¨‹æ± ] é ç†±å®Œæˆï¼Œè€—æ™‚: {warmup_time:.3f} ç§’")
        return warmup_time

    def run_serial(self, video_path, max_frames):
        """åºåˆ—æ¨¡å¼"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return
        
        if self.player_model is None or self.court_model is None:
            self.load_models()
            
        frame_count = 0
        player_times = []
        court_times = []
        
        start_total = time.time()
        while frame_count < max_frames:
            ret, frame = cap.read()
            if not ret:
                break

            with torch.no_grad():
                start = time.time()
                player_results = self.player_model.track(source=frame, conf=0.3, persist=True, tracker="bytetrack.yaml")
                player_end = time.time()
                player_time = player_end - start
                player_times.append(player_time)

                court_results = self.court_model.track(source=frame, conf=0.25, persist=True, tracker="bytetrack.yaml")
                court_end = time.time()
                court_time = court_end - player_end
                court_times.append(court_time)
                
                print(f"[åºåˆ—æ¨¡å¼] Frame-{frame_count}: çƒå“¡ {player_time:.3f}s, çƒå ´ {court_time:.3f}s")
                    
            frame_count += 1
            
        end_total = time.time()
        total_time = end_total - start_total
        avg_player_time = sum(player_times) / len(player_times) if player_times else 0
        avg_court_time = sum(court_times) / len(court_times) if court_times else 0
        
        cap.release()
        return {
            "total_time": total_time,
            "frames": frame_count,
            "avg_player_time": avg_player_time,
            "avg_court_time": avg_court_time
        }

    def run_threading(self, video_path, max_frames):
        """å¤šåŸ·è¡Œç·’æ¨¡å¼"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return

        if self.player_model is None or self.court_model is None:
            self.load_models()

        frames = []
        frame_count = 0
        while frame_count < max_frames:
            ret, frame = cap.read()
            if not ret:
                break
            frames.append(frame.copy())
            frame_count += 1
        cap.release()
        
        player_times = []
        court_times = []
        actual_frame_times = []  # å¯¦éš›æ¯å¹€ä¸¦è¡Œè™•ç†æ™‚é–“
        total_start = time.time()
        
        for i, frame in enumerate(frames):
            frame_start = time.time()
            p_time = [0]
            c_time = [0]
            
            def _run_player():
                with torch.no_grad():
                    start = time.time()
                    self.player_model.track(source=frame, conf=0.3, persist=True, tracker="bytetrack.yaml")
                    p_time[0] = time.time() - start
            
            def _run_court():
                with torch.no_grad():
                    start = time.time()
                    self.court_model.track(source=frame, conf=0.25, persist=True, tracker="bytetrack.yaml")
                    c_time[0] = time.time() - start
            
            t1 = threading.Thread(target=_run_player)
            t2 = threading.Thread(target=_run_court)
            t1.start()
            t2.start()
            t1.join()
            t2.join()
            
            frame_end = time.time()
            actual_frame_time = frame_end - frame_start

            player_times.append(p_time[0])
            court_times.append(c_time[0])
            actual_frame_times.append(actual_frame_time)

            # è¨ˆç®—é€™ä¸€å¹€çš„æ½›åœ¨èŠ±è²»ï¼ˆåºåˆ—æ¨¡å¼è€—æ™‚ - ä¸¦è¡Œæ¨¡å¼è€—æ™‚ï¼‰
            serial_time = p_time[0] + c_time[0]
            potential_cost = serial_time - actual_frame_time

            print(f"[å¤šåŸ·è¡Œç·’] Frame-{i}: çƒå“¡ {p_time[0]:.3f}s, çƒå ´ {c_time[0]:.3f}s, å¯¦éš› {actual_frame_time:.3f}s, æ½›åœ¨èŠ±è²» {potential_cost:.3f}s")
        
        total_time = time.time() - total_start
        avg_player_time = sum(player_times) / len(player_times) if player_times else 0
        avg_court_time = sum(court_times) / len(court_times) if court_times else 0
        avg_actual_time = sum(actual_frame_times) / len(actual_frame_times) if actual_frame_times else 0
        
        # å¹³å‡æ½›åœ¨èŠ±è²» = å¹³å‡åºåˆ—è€—æ™‚ - å¹³å‡ä¸¦è¡Œè€—æ™‚
        avg_serial_time = avg_player_time + avg_court_time
        avg_potential_cost = avg_serial_time - avg_actual_time
        
        return {
            "total_time": total_time,
            "frames": len(frames),
            "avg_player_time": avg_player_time,
            "avg_court_time": avg_court_time,
            "avg_potential_cost": avg_potential_cost
        }

    def run_multiprocess(self, video_path, max_frames):
        """å¤šé€²ç¨‹æ¨¡å¼"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return

        frames = []
        count = 0
        while count < max_frames:
            ret, frame = cap.read()
            if not ret:
                break
            frames.append(frame.copy())
            count += 1
        cap.release()

        if not frames:
            return

        if sys.platform in ['win32', 'darwin']:
            mp.set_start_method("spawn", force=True)

        player_times = []
        court_times = []
        actual_frame_times = []  # å¯¦éš›æ¯å¹€ä¸¦è¡Œè™•ç†æ™‚é–“
        total_start = time.time()

        for i, frame in enumerate(frames):
            frame_start = time.time()
            manager = mp.Manager()
            result_dict = manager.dict()

            p_player = mp.Process(
                target=player_process_worker,
                args=([frame], result_dict, self.player_model_path, self.device)
            )
            p_court = mp.Process(
                target=court_process_worker,
                args=([frame], result_dict, self.court_model_path, self.device)
            )

            p_player.start()
            p_court.start()
            p_player.join()
            p_court.join()

            frame_end = time.time()
            actual_frame_time = frame_end - frame_start

            pt = result_dict['player_times'][0]
            ct = result_dict['court_times'][0]
            player_times.append(pt)
            court_times.append(ct)
            actual_frame_times.append(actual_frame_time)

            # è¨ˆç®—é€™ä¸€å¹€çš„æ½›åœ¨èŠ±è²»ï¼ˆåºåˆ—æ¨¡å¼è€—æ™‚ - ä¸¦è¡Œæ¨¡å¼è€—æ™‚ï¼‰
            serial_time = pt + ct
            potential_cost = serial_time - actual_frame_time

            print(f"[å¤šé€²ç¨‹] Frame-{i}: çƒå“¡ {pt:.3f}s, çƒå ´ {ct:.3f}s, å¯¦éš› {actual_frame_time:.3f}s, æ½›åœ¨èŠ±è²» {potential_cost:.3f}s")

        total_time = time.time() - total_start
        avg_player_time = sum(player_times)/len(player_times) if player_times else 0
        avg_court_time = sum(court_times)/len(court_times) if court_times else 0
        avg_actual_time = sum(actual_frame_times) / len(actual_frame_times) if actual_frame_times else 0

        # å¹³å‡æ½›åœ¨èŠ±è²» = å¹³å‡åºåˆ—è€—æ™‚ - å¹³å‡ä¸¦è¡Œè€—æ™‚
        avg_serial_time = avg_player_time + avg_court_time
        avg_potential_cost = avg_serial_time - avg_actual_time

        return {
            "total_time": total_time,
            "frames": len(frames),
            "avg_player_time": avg_player_time,
            "avg_court_time": avg_court_time,
            "avg_potential_cost": avg_potential_cost
        }

    def run_queue_multiprocess(self, video_path, max_frames):
        """ä½‡åˆ—å¤šé€²ç¨‹æ¨¡å¼"""
        ctx = mp.get_context("spawn")

        player_task_queue = ctx.Queue(maxsize=10)
        court_task_queue = ctx.Queue(maxsize=10)
        result_queue = ctx.Queue()

        p_player = ctx.Process(
            target=player_queue_worker,
            args=(player_task_queue, result_queue, self.player_model_path, self.device)
        )
        p_court = ctx.Process(
            target=court_queue_worker,
            args=(court_task_queue, result_queue, self.court_model_path, self.device)
        )
        p_player.daemon = True
        p_court.daemon = True
        
        p_player.start()
        p_court.start()

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return
        
        frames = []
        for i in range(max_frames):
            ret, frame = cap.read()
            if not ret:
                if frames:
                    frames.append(frames[-1].copy())
                break
            frames.append(frame.copy())
        cap.release()
        
        start_total = time.time()
        player_times = {}
        court_times = {}
        actual_frame_times = []  # å¯¦éš›æ¯å¹€ä¸¦è¡Œè™•ç†æ™‚é–“

        for frame_idx, frame in enumerate(frames):
            frame_start = time.time()
            player_task_queue.put((frame_idx, frame.copy()))
            court_task_queue.put((frame_idx, frame.copy()))

            frame_results = {}
            got_results = 0
            while got_results < 2:
                typ, idx, _, t = result_queue.get()
                if idx == frame_idx:
                    frame_results[typ] = t
                    got_results += 1
                    if typ == 'player':
                        player_times[idx] = t
                    else:
                        court_times[idx] = t

            frame_end = time.time()
            actual_frame_time = frame_end - frame_start
            actual_frame_times.append(actual_frame_time)

            # è¨ˆç®—é€™ä¸€å¹€çš„æ½›åœ¨èŠ±è²»ï¼ˆåºåˆ—æ¨¡å¼è€—æ™‚ - ä¸¦è¡Œæ¨¡å¼è€—æ™‚ï¼‰
            pt = frame_results.get('player', 0)
            ct = frame_results.get('court', 0)
            serial_time = pt + ct
            potential_cost = serial_time - actual_frame_time

            print(f"[ä½‡åˆ—å¤šé€²ç¨‹] Frame-{frame_idx}: çƒå“¡ {pt:.3f}s, çƒå ´ {ct:.3f}s, å¯¦éš› {actual_frame_time:.3f}s, æ½›åœ¨èŠ±è²» {potential_cost:.3f}s")

        player_task_queue.put(None)
        court_task_queue.put(None)

        p_player.join(timeout=3)
        p_court.join(timeout=3)

        if p_player.is_alive():
            p_player.terminate()
        if p_court.is_alive():
            p_court.terminate()
            
        end_total = time.time()
        total_time = end_total - start_total
        
        avg_player_time = sum(player_times.values()) / len(player_times) if player_times else 0
        avg_court_time = sum(court_times.values()) / len(court_times) if court_times else 0
        avg_actual_time = sum(actual_frame_times) / len(actual_frame_times) if actual_frame_times else 0
        
        # å¹³å‡æ½›åœ¨èŠ±è²» = å¹³å‡åºåˆ—è€—æ™‚ - å¹³å‡ä¸¦è¡Œè€—æ™‚
        avg_serial_time = avg_player_time + avg_court_time
        avg_potential_cost = avg_serial_time - avg_actual_time
        
        return {
            "total_time": total_time,
            "frames": len(frames),
            "avg_player_time": avg_player_time,
            "avg_court_time": avg_court_time,
            "avg_potential_cost": avg_potential_cost
        }

    def run_improved_threading(self, video_path, max_frames):
        """æ”¹é€²åŸ·è¡Œç·’æ± æ¨¡å¼"""
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return

        if self.player_model is None or self.court_model is None:
            self.load_models()

        frames = []
        frame_count = 0
        while frame_count < max_frames:
            ret, frame = cap.read()
            if not ret:
                break
            frames.append(frame.copy())
            frame_count += 1
        cap.release()

        if not frames:
            return

        player_times = []
        court_times = []
        actual_frame_times = []  # å¯¦éš›æ¯å¹€ä¸¦è¡Œè™•ç†æ™‚é–“

        thread_local = threading.local()

        def get_player_model():
            if not hasattr(thread_local, 'player_model'):
                thread_local.player_model = self.player_model
            return thread_local.player_model

        def get_court_model():
            if not hasattr(thread_local, 'court_model'):
                thread_local.court_model = self.court_model
            return thread_local.court_model

        def process_player(frame, frame_idx):
            model = get_player_model()
            with torch.no_grad():
                start = time.time()
                result = model.track(source=frame, conf=0.3, persist=True, tracker="bytetrack.yaml")
                elapsed = time.time() - start
                print(f"[ThreadPool] Frame-{frame_idx} çƒå“¡æª¢æ¸¬å®Œæˆï¼Œè€—æ™‚: {elapsed:.3f} ç§’")
                return result, elapsed

        def process_court(frame, frame_idx):
            model = get_court_model()
            with torch.no_grad():
                start = time.time()
                result = model.track(source=frame, conf=0.25, persist=True, tracker="bytetrack.yaml")
                elapsed = time.time() - start
                print(f"[ThreadPool] Frame-{frame_idx} çƒå ´æª¢æ¸¬å®Œæˆï¼Œè€—æ™‚: {elapsed:.3f} ç§’")
                return result, elapsed

        total_start = time.time()

        with ThreadPoolExecutor(max_workers=2) as executor:
            for i, frame in enumerate(frames):
                frame_start = time.time()
                player_future = executor.submit(process_player, frame, i)
                court_future = executor.submit(process_court, frame, i)

                player_result, player_time = player_future.result()
                court_result, court_time = court_future.result()

                frame_end = time.time()
                actual_frame_time = frame_end - frame_start

                player_times.append(player_time)
                court_times.append(court_time)
                actual_frame_times.append(actual_frame_time)

                # è¨ˆç®—é€™ä¸€å¹€çš„æ½›åœ¨èŠ±è²»ï¼ˆåºåˆ—æ¨¡å¼è€—æ™‚ - ä¸¦è¡Œæ¨¡å¼è€—æ™‚ï¼‰
                serial_time = player_time + court_time
                potential_cost = serial_time - actual_frame_time

                print(f"[ThreadPool] Frame-{i} å®Œæˆ: çƒå“¡ {player_time:.3f}s, çƒå ´ {court_time:.3f}s, å¯¦éš› {actual_frame_time:.3f}s, æ½›åœ¨èŠ±è²» {potential_cost:.3f}s")

        total_time = time.time() - total_start
        avg_player_time = sum(player_times) / len(player_times) if player_times else 0
        avg_court_time = sum(court_times) / len(court_times) if court_times else 0
        avg_actual_time = sum(actual_frame_times) / len(actual_frame_times) if actual_frame_times else 0

        # å¹³å‡æ½›åœ¨èŠ±è²» = å¹³å‡åºåˆ—è€—æ™‚ - å¹³å‡ä¸¦è¡Œè€—æ™‚
        avg_serial_time = avg_player_time + avg_court_time
        avg_potential_cost = avg_serial_time - avg_actual_time

        return {
            "total_time": total_time,
            "frames": len(frames),
            "avg_player_time": avg_player_time,
            "avg_court_time": avg_court_time,
            "avg_potential_cost": avg_potential_cost
        }

    def run_mp_pool(self, video_path, max_frames):
        """å¤šé€²ç¨‹æ± æ¨¡å¼ - å«é ç†±æ©Ÿåˆ¶ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
        from concurrent.futures import ProcessPoolExecutor

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            return

        frames = []
        count = 0
        while count < max_frames:
            ret, frame = cap.read()
            if not ret:
                break
            frames.append(frame.copy())
            count += 1
        cap.release()

        if not frames:
            return

        print(f"[å¤šé€²ç¨‹æ± ] ä½¿ç”¨ 2 å€‹å·¥ä½œé€²ç¨‹ (é€å¹€åŒæ­¥)")

        # ğŸ”¥ é—œéµä¿®æ­£ï¼šåœ¨åŒä¸€å€‹é€²ç¨‹æ± ä¸­é€²è¡Œé ç†±å’Œæ­£å¼è™•ç†
        with ProcessPoolExecutor(max_workers=2) as executor:
            # é ç†±éšæ®µ
            print("[å¤šé€²ç¨‹æ± ] é–‹å§‹é ç†±æ¨¡å‹...")
            warmup_start = time.time()

            dummy_frame = np.zeros((480, 640, 3), dtype=np.uint8)

            # é ç†±å…©å€‹worker
            player_warmup = executor.submit(
                player_pool_worker_frame_sync,
                (dummy_frame, -1, self.player_model_path, self.device)
            )
            court_warmup = executor.submit(
                court_pool_worker_frame_sync,
                (dummy_frame, -1, self.court_model_path, self.device)
            )

            # ç­‰å¾…é ç†±å®Œæˆ
            player_warmup.result()
            court_warmup.result()

            warmup_time = time.time() - warmup_start
            print(f"[å¤šé€²ç¨‹æ± ] é ç†±å®Œæˆï¼Œè€—æ™‚: {warmup_time:.3f} ç§’")

            # ğŸ¯ æ­£å¼æ¸¬é‡é–‹å§‹ï¼ˆåœ¨åŒä¸€å€‹é€²ç¨‹æ± ä¸­ï¼‰
            measurement_start = time.time()
            player_times = []
            court_times = []
            actual_frame_times = []  # å¯¦éš›æ¯å¹€ä¸¦è¡Œè™•ç†æ™‚é–“

            # æ­£å¼è™•ç†æ‰€æœ‰å¹€
            for i, frame in enumerate(frames):
                frame_start = time.time()
                player_future = executor.submit(
                    player_pool_worker_frame_sync,
                    (frame, i, self.player_model_path, self.device)
                )
                court_future = executor.submit(
                    court_pool_worker_frame_sync,
                    (frame, i, self.court_model_path, self.device)
                )

                try:
                    player_result_type, player_idx, player_result, player_time = player_future.result()
                    court_result_type, court_idx, court_result, court_time = court_future.result()

                    frame_end = time.time()
                    actual_frame_time = frame_end - frame_start

                    player_times.append(player_time)
                    court_times.append(court_time)
                    actual_frame_times.append(actual_frame_time)

                    # è¨ˆç®—é€™ä¸€å¹€çš„æ½›åœ¨èŠ±è²»ï¼ˆåºåˆ—æ¨¡å¼è€—æ™‚ - ä¸¦è¡Œæ¨¡å¼è€—æ™‚ï¼‰
                    serial_time = player_time + court_time
                    potential_cost = serial_time - actual_frame_time

                    print(f"[å¤šé€²ç¨‹æ± ] Frame-{i} å®Œæˆ: çƒå“¡ {player_time:.3f}s, çƒå ´ {court_time:.3f}s, å¯¦éš› {actual_frame_time:.3f}s, æ½›åœ¨èŠ±è²» {potential_cost:.3f}s")

                except Exception as e:
                    print(f"è™•ç†Frame-{i}æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue

        total_time = time.time() - measurement_start
        avg_player_time = sum(player_times) / len(player_times) if player_times else 0
        avg_court_time = sum(court_times) / len(court_times) if court_times else 0
        avg_actual_time = sum(actual_frame_times) / len(actual_frame_times) if actual_frame_times else 0

        # å¹³å‡æ½›åœ¨èŠ±è²» = å¹³å‡åºåˆ—è€—æ™‚ - å¹³å‡ä¸¦è¡Œè€—æ™‚
        avg_serial_time = avg_player_time + avg_court_time
        avg_potential_cost = avg_serial_time - avg_actual_time

        print(f"å¤šé€²ç¨‹æ± æ¨¡å¼å®Œæˆï¼Œæ¸¬é‡è€—æ™‚: {total_time:.3f} ç§’ï¼Œé ç†±è€—æ™‚: {warmup_time:.3f} ç§’")

        return {
            "total_time": total_time,
            "frames": len(frames),
            "avg_player_time": avg_player_time,
            "avg_court_time": avg_court_time,
            "avg_potential_cost": avg_potential_cost,
            "warmup_time": warmup_time
        }

class YOLODetectionApp:
    def __init__(self, root):
        self.root = root
        self.root.title("YOLO å¤šæ©Ÿåˆ¶å½±ç‰‡è¾¨è­˜")
        self.root.geometry("800x600")
        
        self.detector = None
        self.results = {}
        
        self._create_widgets()

    def _create_widgets(self):
        main_frame = ttk.Frame(self.root, padding=10)
        main_frame.pack(fill=tk.BOTH, expand=True)

        settings_frame = ttk.LabelFrame(main_frame, text="è¨­å®š", padding=10)
        settings_frame.pack(fill=tk.X, pady=5)
        
        # çƒå“¡æ¨¡å‹è·¯å¾‘
        ttk.Label(settings_frame, text="çƒå“¡æ¨¡å‹è·¯å¾‘:").grid(row=0, column=0, sticky=tk.W, padx=5, pady=5)
        self.player_model_path_var = tk.StringVar(value="best_demo_v2.pt")
        ttk.Entry(settings_frame, textvariable=self.player_model_path_var, width=40).grid(row=0, column=1, sticky=tk.W+tk.E, padx=5, pady=5)
        ttk.Button(settings_frame, text="ç€è¦½", command=lambda: self._browse_model("player")).grid(row=0, column=2, padx=5, pady=5)
        
        # çƒå ´æ¨¡å‹è·¯å¾‘
        ttk.Label(settings_frame, text="çƒå ´æ¨¡å‹è·¯å¾‘:").grid(row=1, column=0, sticky=tk.W, padx=5, pady=5)
        self.court_model_path_var = tk.StringVar(value="Court_best.pt")
        ttk.Entry(settings_frame, textvariable=self.court_model_path_var, width=40).grid(row=1, column=1, sticky=tk.W+tk.E, padx=5, pady=5)
        ttk.Button(settings_frame, text="ç€è¦½", command=lambda: self._browse_model("court")).grid(row=1, column=2, padx=5, pady=5)
        
        # å½±ç‰‡è·¯å¾‘
        ttk.Label(settings_frame, text="å½±ç‰‡è·¯å¾‘:").grid(row=2, column=0, sticky=tk.W, padx=5, pady=5)
        self.video_path_var = tk.StringVar()
        ttk.Entry(settings_frame, textvariable=self.video_path_var, width=40).grid(row=2, column=1, sticky=tk.W+tk.E, padx=5, pady=5)
        ttk.Button(settings_frame, text="ç€è¦½", command=self._browse_video).grid(row=2, column=2, padx=5, pady=5)
        
        # å½±æ ¼æ•¸é‡
        ttk.Label(settings_frame, text="è™•ç†å½±æ ¼æ•¸:").grid(row=3, column=0, sticky=tk.W, padx=5, pady=5)
        self.frames_var = tk.IntVar(value=10)
        ttk.Entry(settings_frame, textvariable=self.frames_var, width=10).grid(row=3, column=1, sticky=tk.W, padx=5, pady=5)
        
        # åŸ·è¡Œæ¨¡å¼
        ttk.Label(settings_frame, text="åŸ·è¡Œæ¨¡å¼:").grid(row=4, column=0, sticky=tk.W, padx=5, pady=5)
        self.mode_var = tk.IntVar(value=MODE_SERIAL)
        modes = [("åºåˆ—æ¨¡å¼", MODE_SERIAL), 
                 ("å¤šåŸ·è¡Œç·’æ¨¡å¼", MODE_THREADING), 
                 ("å¤šé€²ç¨‹æ¨¡å¼", MODE_MULTIPROCESS), 
                 ("ä½‡åˆ—å¤šé€²ç¨‹æ¨¡å¼", MODE_QUEUE),
                 ("æ”¹é€²åŸ·è¡Œç·’æ± æ¨¡å¼", MODE_IMPROVED_THREADING),
                 ("å¤šé€²ç¨‹æ± æ¨¡å¼", MODE_MP_POOL)]
                 
        mode_frame = ttk.Frame(settings_frame)
        mode_frame.grid(row=4, column=1, columnspan=2, sticky=tk.W, padx=5, pady=5)
        
        for i, (text, value) in enumerate(modes):
            ttk.Radiobutton(mode_frame, text=text, variable=self.mode_var, value=value).grid(row=0, column=i, padx=5)
            
        # æŒ‰éˆ•å€åŸŸ
        button_frame = ttk.Frame(main_frame)
        button_frame.pack(fill=tk.X, pady=10)
        ttk.Button(button_frame, text="é è¼‰å…¥æ¨¡å‹", command=self._preload_models).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="é ç†±å¤šé€²ç¨‹æ± ", command=self._warmup_mp_pool).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="é–‹å§‹è™•ç†", command=self._start_detection).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="æ¸…é™¤çµæœ", command=self._clear_results).pack(side=tk.LEFT, padx=5)
        
        # çµæœé¡¯ç¤ºå€åŸŸ
        results_frame = ttk.LabelFrame(main_frame, text="çµæœ", padding=10)
        results_frame.pack(fill=tk.BOTH, expand=True, pady=5)
        
        # æ–‡å­—è¼¸å‡º
        self.log_text = tk.Text(results_frame, height=10, state=tk.DISABLED)
        self.log_text.pack(fill=tk.BOTH, expand=True, side=tk.LEFT)
        
        scrollbar = ttk.Scrollbar(results_frame, command=self.log_text.yview)
        scrollbar.pack(fill=tk.Y, side=tk.RIGHT)
        self.log_text.config(yscrollcommand=scrollbar.set)
        
        # ç‹€æ…‹åˆ—
        self.status_var = tk.StringVar(value="å°±ç·’")
        status_bar = ttk.Label(main_frame, textvariable=self.status_var, relief=tk.SUNKEN, anchor=tk.W)
        status_bar.pack(fill=tk.X, side=tk.BOTTOM, pady=5)
        
    def _browse_model(self, model_type):
        """ç€è¦½é¸æ“‡æ¨¡å‹æª”æ¡ˆ"""
        filename = filedialog.askopenfilename(
            title=f"é¸æ“‡{model_type}æ¨¡å‹",
            filetypes=[("YOLOæ¨¡å‹", "*.pt"), ("æ‰€æœ‰æª”æ¡ˆ", "*.*")]
        )
        if filename:
            if model_type == "player":
                self.player_model_path_var.set(filename)
            elif model_type == "court":
                self.court_model_path_var.set(filename)
            
    def _browse_video(self):
        """ç€è¦½é¸æ“‡å½±ç‰‡æª”æ¡ˆ"""
        filename = filedialog.askopenfilename(
            title="é¸æ“‡å½±ç‰‡æª”æ¡ˆ",
            filetypes=[("å½±ç‰‡æª”æ¡ˆ", "*.mp4 *.avi *.mov"), ("æ‰€æœ‰æª”æ¡ˆ", "*.*")]
        )
        if filename:
            self.video_path_var.set(filename)
    
    def _preload_models(self):
        """é è¼‰å…¥æ¨¡å‹"""
        player_model_path = self.player_model_path_var.get()
        court_model_path = self.court_model_path_var.get()
        
        if not player_model_path or not court_model_path:
            messagebox.showwarning("è­¦å‘Š", "è«‹æŒ‡å®šå…©å€‹æ¨¡å‹è·¯å¾‘")
            return
            
        if not os.path.exists(player_model_path):
            messagebox.showerror("éŒ¯èª¤", f"çƒå“¡æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {player_model_path}")
            return
            
        if not os.path.exists(court_model_path):
            messagebox.showerror("éŒ¯èª¤", f"çƒå ´æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {court_model_path}")
            return
        
        self.status_var.set("æ­£åœ¨é è¼‰å…¥æ¨¡å‹...")
        self.root.update()

        if self.detector is None:
            self.detector = YOLODetector(player_model_path, court_model_path)
        self.detector.load_models()
        
        self.status_var.set("æ¨¡å‹å·²é è¼‰å…¥")
        self._log_message("æ¨¡å‹å·²é è¼‰å…¥ï¼Œç¾åœ¨å¯ä»¥é–‹å§‹æ¸¬è©¦äº†ã€‚")
    
    def _warmup_mp_pool(self):
        """é ç†±å¤šé€²ç¨‹æ± æ¨¡å‹"""
        player_model_path = self.player_model_path_var.get()
        court_model_path = self.court_model_path_var.get()

        if not player_model_path or not court_model_path:
            messagebox.showwarning("è­¦å‘Š", "è«‹æŒ‡å®šå…©å€‹æ¨¡å‹è·¯å¾‘")
            return

        if not os.path.exists(player_model_path):
            messagebox.showerror("éŒ¯èª¤", f"çƒå“¡æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {player_model_path}")
            return

        if not os.path.exists(court_model_path):
            messagebox.showerror("éŒ¯èª¤", f"çƒå ´æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {court_model_path}")
            return

        self.status_var.set("æ­£åœ¨é ç†±å¤šé€²ç¨‹æ± ...")
        self.root.update()

        if self.detector is None:
            self.detector = YOLODetector(player_model_path, court_model_path)

        try:
            warmup_time = self.detector.warmup_mp_pool_models()
            self.status_var.set("å¤šé€²ç¨‹æ± å·²é ç†±")
            self._log_message(f"å¤šé€²ç¨‹æ± é ç†±å®Œæˆï¼Œè€—æ™‚: {warmup_time:.3f} ç§’")
        except Exception as e:
            self.status_var.set("é ç†±å¤±æ•—")
            self._log_message(f"é ç†±å¤±æ•—: {str(e)}")
            messagebox.showerror("éŒ¯èª¤", f"é ç†±å¤±æ•—:\n{str(e)}")

    def _start_detection(self):
        """é–‹å§‹åµæ¸¬è™•ç†"""
        video_path = self.video_path_var.get()
        if not video_path:
            messagebox.showwarning("è­¦å‘Š", "è«‹é¸æ“‡å½±ç‰‡æª”æ¡ˆ")
            return
            
        if not os.path.exists(video_path):
            messagebox.showerror("éŒ¯èª¤", f"å½±ç‰‡æª”æ¡ˆä¸å­˜åœ¨: {video_path}")
            return
            
        player_model_path = self.player_model_path_var.get()
        court_model_path = self.court_model_path_var.get()
        
        if not player_model_path or not court_model_path:
            messagebox.showwarning("è­¦å‘Š", "è«‹æŒ‡å®šå…©å€‹æ¨¡å‹è·¯å¾‘")
            return
            
        if not os.path.exists(player_model_path):
            messagebox.showerror("éŒ¯èª¤", f"çƒå“¡æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {player_model_path}")
            return
            
        if not os.path.exists(court_model_path):
            messagebox.showerror("éŒ¯èª¤", f"çƒå ´æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {court_model_path}")
            return

        self.status_var.set("è™•ç†ä¸­...")
        self.root.update()

        if self.detector is None:
            self.detector = YOLODetector(player_model_path, court_model_path)
            self.detector.load_models()

        mode = self.mode_var.get()
        max_frames = self.frames_var.get()

        threading.Thread(target=self._run_detection, args=(mode, video_path, max_frames), daemon=True).start()
        
    def _run_detection(self, mode, video_path, max_frames):
        """åŸ·è¡Œé¸å®šçš„åµæ¸¬æ¨¡å¼"""
        try:
            self.results = {}

            self._log_message(f"é–‹å§‹åŸ·è¡Œï¼Œæ¨¡å¼: {self._get_mode_name(mode)}, å½±æ ¼æ•¸: {max_frames}")
            
            if mode == MODE_SERIAL:
                self._log_message("åŸ·è¡Œåºåˆ—æ¨¡å¼...")
                self.results = self.detector.run_serial(video_path, max_frames)
            elif mode == MODE_THREADING:
                self._log_message("åŸ·è¡Œå¤šåŸ·è¡Œç·’æ¨¡å¼...")
                self.results = self.detector.run_threading(video_path, max_frames)
            elif mode == MODE_MULTIPROCESS:
                self._log_message("åŸ·è¡Œå¤šé€²ç¨‹æ¨¡å¼...")
                self.results = self.detector.run_multiprocess(video_path, max_frames)
            elif mode == MODE_QUEUE:
                self._log_message("åŸ·è¡Œä½‡åˆ—å¤šé€²ç¨‹æ¨¡å¼...")
                self.results = self.detector.run_queue_multiprocess(video_path, max_frames)
            elif mode == MODE_IMPROVED_THREADING:
                self._log_message("åŸ·è¡Œæ”¹é€²çš„å¤šåŸ·è¡Œç·’æ¨¡å¼...")
                self.results = self.detector.run_improved_threading(video_path, max_frames)
            elif mode == MODE_MP_POOL:
                self._log_message("åŸ·è¡Œå¤šé€²ç¨‹æ± æ¨¡å¼...")
                self.results = self.detector.run_mp_pool(video_path, max_frames)
            else:
                messagebox.showerror("éŒ¯èª¤", f"æœªçŸ¥çš„åŸ·è¡Œæ¨¡å¼: {mode}")
                return

            if "total_time" in self.results:
                total_time = self.results["total_time"]
                frames = self.results.get("frames", 0)
                avg_player_time = self.results.get("avg_player_time", 0)
                avg_court_time = self.results.get("avg_court_time", 0)
                warmup_time = self.results.get("warmup_time", 0)
                avg_potential_cost = self.results.get("avg_potential_cost", 0)

                self._log_message(f"\n===== {self._get_mode_name(mode)} åŸ·è¡Œçµæœ =====")
                self._log_message(f"ç¸½è™•ç†æ™‚é–“: {total_time:.3f} ç§’")
                if warmup_time > 0:
                    self._log_message(f"é ç†±æ™‚é–“: {warmup_time:.3f} ç§’ (ä¸è¨ˆå…¥æ¸¬é‡)")
                self._log_message(f"è™•ç†ç¸½å¹€æ•¸: {frames} å¹€")
                self._log_message(f"å¹³å‡æ¯å¹€è€—æ™‚: {total_time/frames:.3f} ç§’ (ç´„ {frames/total_time:.2f} FPS)")
                self._log_message(f"å¹³å‡çƒå“¡åµæ¸¬è€—æ™‚: {avg_player_time:.3f} ç§’")
                self._log_message(f"å¹³å‡çƒå ´åµæ¸¬è€—æ™‚: {avg_court_time:.3f} ç§’")

                # é¡¯ç¤ºå¹³å‡æ½›åœ¨èŠ±è²» (åƒ…éåºåˆ—æ¨¡å¼)
                if mode != MODE_SERIAL and avg_potential_cost > 0:
                    self._log_message(f"å¹³å‡æ½›åœ¨èŠ±è²» (ä¸¦è¡Œç¯€çœæ™‚é–“): {avg_potential_cost:.3f} ç§’")

            self.root.after(0, lambda: self.status_var.set("å·²å®Œæˆ"))

        except Exception as e:
            self._log_message(f"éŒ¯èª¤: {str(e)}")
            import traceback
            self._log_message(traceback.format_exc())
            self.root.after(0, lambda: self.status_var.set("ç™¼ç”ŸéŒ¯èª¤"))
            
    def _get_mode_name(self, mode):
        """æ ¹æ“šæ¨¡å¼IDç²å–æ¨¡å¼åç¨±"""
        mode_names = {
            MODE_SERIAL: "åºåˆ—æ¨¡å¼",
            MODE_THREADING: "å¤šåŸ·è¡Œç·’æ¨¡å¼",
            MODE_MULTIPROCESS: "å¤šé€²ç¨‹æ¨¡å¼",
            MODE_QUEUE: "ä½‡åˆ—å¤šé€²ç¨‹æ¨¡å¼",
            MODE_IMPROVED_THREADING: "æ”¹é€²çš„å¤šåŸ·è¡Œç·’æ¨¡å¼",
            MODE_MP_POOL: "å¤šé€²ç¨‹æ± æ¨¡å¼"
        }
        return mode_names.get(mode, "æœªçŸ¥æ¨¡å¼")
    
    def _log_message(self, message):
        """è¨˜éŒ„è¨Šæ¯åˆ°æ–‡å­—æ¡†"""
        self.log_text.config(state=tk.NORMAL)
        self.log_text.insert(tk.END, message + "\n")
        self.log_text.see(tk.END)
        self.log_text.config(state=tk.DISABLED)
        print(message)
        
    def _clear_results(self):
        """æ¸…é™¤çµæœé¡¯ç¤º"""
        self.log_text.config(state=tk.NORMAL)
        self.log_text.delete(1.0, tk.END)
        self.log_text.config(state=tk.DISABLED)
        self.results = {}
        self.status_var.set("å°±ç·’")

if __name__ == "__main__":
    if sys.platform in ['win32', 'darwin']:
        try:
            mp.set_start_method("spawn", force=True)
        except RuntimeError:
            pass
    
    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'Arial Unicode MS', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False

    parser = argparse.ArgumentParser(description='YOLOå…­ç¨®æª¢æ¸¬æ©Ÿåˆ¶')
    parser.add_argument('--mode', type=int, choices=[0, 1, 2, 3, 4, 5],
                      help='åµæ¸¬æ¨¡å¼: 0=åºåˆ—, 1=å¤šåŸ·è¡Œç·’, 2=å¤šé€²ç¨‹, 3=ä½‡åˆ—å¤šé€²ç¨‹, 4=æ”¹é€²åŸ·è¡Œç·’æ± , 5=å¤šé€²ç¨‹æ± ')
    parser.add_argument('--frames', type=int, default=10, help='è¦è™•ç†çš„å½±æ ¼æ•¸')
    parser.add_argument('--video', type=str, help='å½±ç‰‡æª”æ¡ˆè·¯å¾‘')
    parser.add_argument('--player_model', type=str, default='best_demo_v2.pt', help='çƒå“¡æ¨¡å‹è·¯å¾‘')
    parser.add_argument('--court_model', type=str, default='Court_best.pt', help='çƒå ´æ¨¡å‹è·¯å¾‘')
    
    args = parser.parse_args()

    root = tk.Tk()
    app = YOLODetectionApp(root)

    if args.video and os.path.exists(args.video):
        app.video_path_var.set(args.video)
        
    if args.player_model and os.path.exists(args.player_model):
        app.player_model_path_var.set(args.player_model)
        
    if args.court_model and os.path.exists(args.court_model):
        app.court_model_path_var.set(args.court_model)
        
    if args.frames > 0:
        app.frames_var.set(args.frames)
        
    if args.mode is not None:
        app.mode_var.set(args.mode)
        if args.video and os.path.exists(args.video):
            root.after(1000, app._preload_models)
            root.after(2000, app._start_detection)
    
    root.mainloop()